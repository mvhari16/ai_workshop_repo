{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78a6553",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de32855f",
   "metadata": {},
   "source": [
    "## Retinal Fundus Multi-Disease Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a7040",
   "metadata": {},
   "source": [
    "# Solution Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c7521",
   "metadata": {},
   "source": [
    "## 1. Importing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97887c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042ae6e",
   "metadata": {},
   "source": [
    "## 2. Reading the CSV train, Test, and Evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c083b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train =pd.read_csv('../Workspace/RFMDI Dataset/Training_Set/RFMiD_Training_Labels.csv')\n",
    "test  =pd.read_csv('../Workspace/RFMDI Dataset/Test_Set/RFMiD_Testing_Labels.csv')\n",
    "val  =pd.read_csv('../Workspace/RFMDI Dataset/Evaluation_Set/RFMiD_Validation_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c923bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1519/1519 [02:14<00:00, 11.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 401/401 [00:39<00:00, 10.23it/s]\n"
     ]
    }
   ],
   "source": [
    "train_abnrml_path='../Workspace/RFMDI Dataset/Training_Set/Training/abnrml'\n",
    "train_nrml_path='../Workspace/RFMDI Dataset/Training_Set/Training/nrml'\n",
    "#for i in range(len(train['ID'])):\n",
    "#    if train['Disease_Risk'][i] == 1:\n",
    "#        shutil.copy(os.path.join(seg_path,str(train['ID'][i])+'.png'),train_abnrml_path)\n",
    "#    elif train['Disease_Risk'][i] == 0:\n",
    "#        shutil.copy(os.path.join(seg_path,str(train['ID'][i])+'.png'),train_nrml_path)\n",
    "\n",
    "x_train=[]\n",
    "for img in tqdm(os.listdir(train_abnrml_path)):    \n",
    "    image_path=train_abnrml_path+\"/\"+img\n",
    "    img_arr=cv2.imread(image_path)\n",
    "    img_arr=cv2.resize(img_arr,(224,224))\n",
    "    x_train.append(img_arr)\n",
    "\n",
    "for img in tqdm(os.listdir(train_nrml_path)):    \n",
    "    image_path=train_nrml_path+\"/\"+img\n",
    "    img_arr=cv2.imread(image_path)\n",
    "    img_arr=cv2.resize(img_arr,(224,224))\n",
    "    x_train.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1843ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 506/506 [00:44<00:00, 11.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 134/134 [00:17<00:00,  7.45it/s]\n"
     ]
    }
   ],
   "source": [
    "test_abnrml_path='../Workspace/RFMDI Dataset/Test_Set/Test/abnrml'\n",
    "test_nrml_path='../Workspace/RFMDI Dataset/Test_Set/Test/nrml'\n",
    "seg_path='../Workspace/RFMDI Dataset/Test_Set/Test'\n",
    "for i in range(len(test['ID'])):\n",
    "    if test['Disease_Risk'][i] == 1:\n",
    "        shutil.copy(os.path.join(seg_path,str(test['ID'][i])+'.png'),test_abnrml_path)\n",
    "    elif test['Disease_Risk'][i] == 0:\n",
    "        shutil.copy(os.path.join(seg_path,str(test['ID'][i])+'.png'),test_nrml_path)\n",
    "\n",
    "x_test=[]\n",
    "for img in tqdm(os.listdir(test_abnrml_path)):    \n",
    "    image_path=test_abnrml_path+\"/\"+img\n",
    "    img_arr=cv2.imread(image_path)\n",
    "    img_arr=cv2.resize(img_arr,(224,224))\n",
    "    x_test.append(img_arr)\n",
    "\n",
    "for img in tqdm(os.listdir(test_nrml_path)):    \n",
    "    image_path=test_nrml_path+\"/\"+img\n",
    "    img_arr=cv2.imread(image_path)\n",
    "    img_arr=cv2.resize(img_arr,(224,224))\n",
    "    x_test.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "115b6d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 506/506 [00:50<00:00, 10.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 134/134 [00:18<00:00,  7.40it/s]\n"
     ]
    }
   ],
   "source": [
    "val_abnrml_path='../Workspace/RFMDI Dataset/Evaluation_Set/Validation/abnrml'\n",
    "val_nrml_path='../Workspace/RFMDI Dataset/Evaluation_Set/Validation/nrml'\n",
    "seg_path='../Workspace/RFMDI Dataset/Test_Set/Test'\n",
    "for i in range(len(test['ID'])):\n",
    "    if val['Disease_Risk'][i] == 1:\n",
    "        shutil.copy(os.path.join(seg_path,str(val['ID'][i])+'.png'),val_abnrml_path)\n",
    "    elif val['Disease_Risk'][i] == 0:\n",
    "        shutil.copy(os.path.join(seg_path,str(val['ID'][i])+'.png'),val_nrml_path)\n",
    "\n",
    "x_val=[]\n",
    "for img in tqdm(os.listdir(val_abnrml_path)):    \n",
    "    image_path=val_abnrml_path+\"/\"+img\n",
    "    img_arr=cv2.imread(image_path)\n",
    "    img_arr=cv2.resize(img_arr,(224,224))\n",
    "    x_val.append(img_arr)\n",
    "\n",
    "for img in tqdm(os.listdir(val_nrml_path)):    \n",
    "    image_path=val_nrml_path+\"/\"+img\n",
    "    img_arr=cv2.imread(image_path)\n",
    "    img_arr=cv2.resize(img_arr,(224,224))\n",
    "    x_val.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d27bb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.array(x_train)\n",
    "test_x=np.array(x_test)\n",
    "val_x=np.array(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ae162a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape\n",
    "test_x.shape\n",
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83322c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x/255.0\n",
    "test_x=test_x/255.0\n",
    "val_x=val_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd6c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c900b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c09a3e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 images belonging to 2 classes.\n",
      "Found 640 images belonging to 2 classes.\n",
      "Found 640 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('../Workspace/RFMDI Dataset/Training_Set/Training',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'sparse')\n",
    "testing_set = train_datagen.flow_from_directory('../Workspace/RFMDI Dataset/Test_Set/Test',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'sparse')\n",
    "valuation_set = train_datagen.flow_from_directory('../Workspace/RFMDI Dataset/Evaluation_Set/Validation',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6bdf9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abnrml': 0, 'nrml': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices\n",
    "testing_set.class_indices\n",
    "valuation_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0b37694",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=training_set.classes\n",
    "test_y=testing_set.classes\n",
    "val_y=valuation_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1081c229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape\n",
    "test_y.shape\n",
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4b9d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77a9f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ed22f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a4e623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg.output)\n",
    "\n",
    "prediction = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "312a6bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 50178     \n",
      "=================================================================\n",
      "Total params: 20,074,562\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb211934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer=\"adam\",\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00547ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)\n",
    "\n",
    "#Early stopping to avoid overfitting of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c32969aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 1151s 19s/step - loss: 0.2726 - accuracy: 0.8786 - val_loss: 0.8229 - val_accuracy: 0.6703\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 1122s 19s/step - loss: 0.3002 - accuracy: 0.8568 - val_loss: 0.7387 - val_accuracy: 0.7734\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 1124s 19s/step - loss: 0.2793 - accuracy: 0.8760 - val_loss: 0.7823 - val_accuracy: 0.7469\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 1123s 19s/step - loss: 0.2423 - accuracy: 0.8979 - val_loss: 0.7430 - val_accuracy: 0.7812\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 1114s 19s/step - loss: 0.2406 - accuracy: 0.8984 - val_loss: 0.7774 - val_accuracy: 0.7719\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 1114s 19s/step - loss: 0.2831 - accuracy: 0.8802 - val_loss: 0.8149 - val_accuracy: 0.7578\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 1113s 19s/step - loss: 0.2492 - accuracy: 0.8969 - val_loss: 0.7834 - val_accuracy: 0.7656\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = tqdm(model.fit(\n",
    "  train_x,\n",
    "  train_y,\n",
    "  validation_data=(val_x,val_y),\n",
    "  epochs=10,\n",
    "  callbacks=[early_stop],\n",
    "  batch_size=32,shuffle=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
